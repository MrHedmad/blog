<!doctype html><html><head lang=en><meta charset=utf-8><meta http-equiv=X-UA-Compatible content="IE=edge"><title>Future Open Research - Open Bytes</title><meta name=viewport content="width=device-width,initial-scale=1">
<meta name=description content="My ideas about what research should look like in a FAIR and Open world"><meta property="og:image" content><meta property="og:url" content="https://mrhedmad.github.io/blog/posts/future_research/"><meta property="og:site_name" content="Open Bytes"><meta property="og:title" content="Future Open Research"><meta property="og:description" content="My ideas about what research should look like in a FAIR and Open world"><meta property="og:locale" content="en_us"><meta property="og:type" content="article"><meta property="article:section" content="posts"><meta property="article:published_time" content="2024-10-25T00:00:00+00:00"><meta property="article:modified_time" content="2024-10-25T00:00:00+00:00"><meta name=twitter:card content="summary"><meta name=twitter:title content="Future Open Research"><meta name=twitter:description content="My ideas about what research should look like in a FAIR and Open world"><script src=https://cdn.jsdelivr.net/npm/feather-icons/dist/feather.min.js></script><link href="https://fonts.googleapis.com/css2?family=IBM+Plex+Mono:ital,wght@1,500&display=swap" rel=stylesheet><link href="https://fonts.googleapis.com/css2?family=Atkinson+Hyperlegible&display=swap" rel=stylesheet><link href="https://fonts.googleapis.com/css?family=Roboto+Mono" rel=stylesheet><link rel=stylesheet type=text/css media=screen href=https://mrhedmad.github.io/blog/css/main.88accdb1b56d650bdf4ccffab56f659967edb0e09f956255e516b6daf06ffdf5.css><link id=darkModeStyle rel=stylesheet type=text/css href=https://mrhedmad.github.io/blog/css/dark.b3ed1a4cd02b1397a340556e323b430fb5cfa721c42fca542dd3109ff099a3fc.css><script>window.MathJax={tex:{inlineMath:[["$","$"],["\\(","\\)"]],displayMath:[["$$","$$"],["[","]"]],processEscapes:!0,processEnvironments:!0},options:{skipHtmlTags:["script","noscript","style","textarea","pre"]},loader:{load:["output/chtml"]}}</script><script type=text/javascript id=MathJax-script async src=https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-svg.js></script></head><body><div class=content><header><div class=main><a href=https://mrhedmad.github.io/blog/>Open Bytes</a></div><nav><a href=/blog/>Home</a>
<a href=/blog/posts>Posts</a>
<a href=/blog/about>About</a></nav></header><main><article><div class=title><h1 class=title>Future Open Research</h1><div class=meta>Posted on Oct 25, 2024</div></div><section class=body><p>In this piece I hope to give an overall view on how I believe the future research &ldquo;flow&rdquo; should look like, given the ideas in the Open Science and FAIR spaces, and how data stewards fit into the overall picture.</p><p>I&rsquo;d like to place a disclaimer here. I am, in no shape or form, thinking that the ideas presented here would be easy to implement. However, I believe that delineating and keeping in mind the <em>golden standard</em> is essential while pursuing it.
These ideas also apply for <em>publicly funded</em> research. Privately funded research might not fit this schema, although I&rsquo;d argue many aspects can be transversal.</p><p><img src=https://i.ibb.co/fG9KkGr/research-flow-dark.png alt="Research Flow"></p><p>First, we can define three large areas in the research process:</p><ul><li>The planning phase, before the project starts, when details about it are defined;</li><li>The research process itself, when experiments are executed;</li><li>The dissemination of the conducted research;</li></ul><p>Data stewards and Open Science principles can help streamline and open up all three steps, creating a new, of fundamentally higher quality, research procedure.
I refer to this proposed structure as &ldquo;Open Research&rdquo; (OR).</p><blockquote><p>I often talk about Structured protocols. You can find more information on them <a href=https://mrhedmad.github.io/mimir/prep/definitions.html>here</a> and <a href=https://mrhedmad.github.io/mimir/prep/protocols.html>here</a>. They are implemented well in the (paid) platform of <a href=https://protocols.io>protocols.io</a>.</p></blockquote><blockquote><p>Bullet points starting with <code>$</code> are implementation questions that have to be effectively adressed before this research flow can be used in practice.</p></blockquote><h2 id=planning>Planning</h2><p>The project planning phase is arguably the most important.
OR begins as any research project does, by having an idea.
This idea, as is routinely done when applying for grants, is often fleshed out and plainly explained in a specific document.
OR extends this idea to every project, big or small, funded through grants or not.</p><p>When an individual or team is committed to the execution of the project, a <em>project space</em> is created with the ability to store project-level documentation and metadata. This platform is then used as a centralized place to effectively plan all the other steps.</p><ul><li>$ Which technology will be used to create the <em>project space</em>?<ul><li><a href=https://osf.io/>https://osf.io/</a> is a possibility.</li></ul></li></ul><p>During this phase, many aspects of the overall project are defined:</p><ul><li>The rationale and assumptions that form the background of the project;</li><li>The ultimate objective of the project, crucially with clear, <em>actionable</em> experimental questions;</li><li>The methods that will be used to achieve the objective(s), in as much detail as this phase allows, including, if needed, the statistical methods that will be applied to the data;<ul><li>A consultation with a statistician is crucial at this point.</li></ul></li><li>What are the expected results, if any.<ul><li>While the practice of <em>expecting a result</em> is arguably negative - it may increase biases or trigger subconscious questionable research practices - it is in the nature of research to expect a particular outcome. It is important therefore to be aware of these potential biases in order to mitigate them.</li></ul></li><li>Where to ask for funding, if it is needed.</li></ul><p>Depending on the scope of the project, this document, the <em>project plan</em>, may be large or small, but it is important to underline that OF prescribes that <em>all</em> projects, of any size, are explicitly planned.</p><ul><li>$ How can this document be structured? Which guidelines (accounting for scope) should be created to support this project?<ul><li>A potential way is to consult pre-registration journals, and re-use their guidelines.</li></ul></li></ul><p>If required, the funding proposal is created and included in the project space.</p><ul><li>$ How can we keep track of all the projects created by the university?<ul><li>The CRIS informational system may be useful in this regard.</li></ul></li></ul><p>Crucially, after the project plan is created, a data steward is assigned to the project. The data steward has the role of guiding the researchers in all aspects regarding data management, from dealing with the fine points of FAIR data implementation to the education of researchers on Open Science concepts.</p><ul><li>$ Of course, the institution would need a group of data stewards to support this step.</li></ul><p>The data steward then begins guiding the group through the creation of a data management plan. The data types that are expected to be handled in the project are defined. Then, the data steward determines if FAIR Implementation Profiles (FIPs) created in the past can be used to deal with the data types that are planned to be encountered during the project.
If relevant FIPs exist, they can be reused or adapted to the current situations. Otherwise, they need to be created by the data steward, and deposited in the FIP archive for later reuse.</p><ul><li>$ What will be contained in a FIP? Where will the FIPs be archived? How can they be made both human- and machine-operable? How can we avoid FIP duplication?</li></ul><p>Once data types, volumes, privacy concerns, corresponding FIPs and all other aspects regarding data management are determined, the data management plan can be redacted, and deposited as a deliverable in the project space.</p><ul><li>$ Which tools can be used to create the DMP? Which tools can help in the preliminary interview?<ul><li>An example is the Data Stewardship Wizard.</li></ul></li></ul><p>After - and only after - the DMP is created, the true research process can begin.</p><h2 id=active-research>Active Research</h2><blockquote><p>It is important to note that I am a researcher in the biological space, so my concept of <em>experiment</em> aligns with this field. I admit my ignorance of other research areas, and, while I try to present these ideas in a field-agnostic way, this discrepancy on conceptualization might cause some concepts presented here to not apply, at least directly, to all research fields.</p></blockquote><p>The research process itself involves running experiments or, in general, gathering and processing knowledge.</p><p>It is crucial that each technically sound experiment or data collection (even if not ultimately useful to the goal of the project) is considered for long term preservation (see, for this, the discard problem).</p><p>Tools such as open notebooks, integrated research environments and others are particularly useful to open up research during this step.
However, due to the fast pace of the research process, the complete transparency at this stage might not be an achievable goal.</p><p>A key aspect that enables future FAIR data creation is the usage of Structured protocols. This allows more or less automatic deposit of experimental data after the experiment is over. Of course, the guiding light during the experimental step is the specific FIP(s) previously defined in the DMP.</p><p>The Hot data produced during this step is temporarily stored in an agile repository.</p><ul><li>$ Where will this temporary storage be?<ul><li>It strongly depends on the FIPs, since data of different kinds will need different hot storage solutions.</li></ul></li></ul><p>The experiments produce considerations, which drive more experiments, and so on. At any point, the DMP may be updated (with the same procedure followed when creating it) if and when new data types need to be used.</p><p>It is useful to apply a standardized structure for the hot data storage, to ease later processing.</p><p>The data steward acts as both support and supervisor, periodically checking if data quality is upheld, and if the processes as detailed in the FIPs are respected regarding data formats, content, etc&mldr;</p><p>OR should explicitly detail every experiment, with a mini-rationale statement and noting down the considerations made on the results.
This has two benefits. First, the researcher must consciously process why each experiment is run, and what information can be derived from it. Secondly, encapsulating data from each experiment individually makes later FAIRification both easier and in some cases possible. Structured protocols should help in this regard, if implemented and followed correctly.</p><blockquote><p>It might be possible to collate FIPs and Structured protocols into a single entity, FAIR Structured Protocols.</p></blockquote><p>All experiments, regardless of &ldquo;positive&rdquo; or &ldquo;negative&rdquo; outcome should be considered for preservation. Only if breaks of the structured protocols are identified it may be fair to outright discard the experimental data due to technical failure.
If the researcher still believes that the experiment failed (regardless of outcome), but a breakage of protocol cannot be clearly determined, the experiment can be retained but marked as potentially faulty.</p><p>A single experiment may be trying to answer more than one question, or might contain internal controls for quality assurance. Additionally, information regarding laboratory quality controls and known confounding factors need to be included in the metadata of the experiment.
It is important that this quality information is properly recorded and reflected in the final metadata.</p><p>The summarize, each experiment &ldquo;block&rsquo; has to carry the following information:</p><ul><li>The rational of the experiment;</li><li>The data itself, potentially already in the structure required by the FIP;</li><li>The (annotated) run information of the Structured protocol used, as well as its version;</li><li>The considerations made by the researcher on the resulting experiment.</li></ul><p>To collate this different information together, an identifier can be used to mark all related files.</p><h2 id=post-experimental-phase>Post-experimental phase</h2><p>After the (main) experimental phase is completed, it is important to collate all experiments which where not discarded (again, regardless of outcome) and all the considerations made on them into a large document which I&rsquo;ll call <em>interpretation</em>.
This document includes everything that was done during the experiment, and may coincide with the laboratory notebook.</p><p>This document, when redacted, will be the starting point of both research articles and the way that data will be ultimately deposited in long-term repositories.</p><p>The researchers leave the data with the data stewards, and may begin writing the manuscript for the publication process.</p><p>The data steward then begins working on archival and long-term preservation of the data.
According to the FIPs, data archival packages are created for the data that requires to be archived (the Discard problem can be re-evaluated here), and expiration dates (if needed) are placed on the data (see, for instance, Access-based lifetime determination).</p><p>When archival packages are ready, they are deposited in the relevant repositories. It is useful to create a space to collate all identifiers of all the data created in a specific project, to preserve the identity of the project itself. A way to do this might be through Nanopublications (see later).</p><ul><li>$ Where will they be deposited in? What shape do they have? What further processing has to be enabled by the structure of the archival packages?<ul><li>All of this information has to be determined while creating the specific FIPs.</li></ul></li></ul><p>Nanopublications are minted from the archival packages, recording the salient metadata and forming a knowledge graph that may be used to access this data again later.</p><p>If software was used to analysed the data, or the project was the development of novel software, this has to be deposited in a static way into some archive.</p><ul><li>$ How can we achieve this? Is Docker enough?</li></ul><p>The interpretation document can also be used (with the help of the original researcher) to derive basic assertions which can become nanopublications, enabling researchers to distill their findings and increasing their own and the community awareness on all of the outcomes of their research, were they expected or otherwise.
These nanopublications can then go and increase the global body of knowledge for further (automated) examination.</p><p>After all data is processed, checked for consistency and archived, and all relevant nanopublications are created and interlinked with the archived data, the project may be considered to be finished. All local data may be deleted, and project spaces closed.</p><p>This marks the end of the project. However, post-project data support may still be needed if third parties require access to data, for example for controlled data. This can be handled by either the data steward, or the researchers themselves.</p><ul><li>$ Who has the legal responsibility over this data? Who is the data curator?<ul><li>In theory, the day-to-day control of the data should be given on the institution, which has a longer lifespan than the individual author (while, of course, keeping authorship rights).</li></ul></li></ul><p>It is important to note that the publication procedure has no influence on whether or not the resulting data and assertions are published. The data is deposited regardless of the attempt at a publication (for a &ldquo;regular&rdquo; project) or not (for, e.g. master theses), and whether or not the manuscript is accepted or not.
This ensures that no insight is lost, regardless of the (potentially fickle) publication procedures.</p><p>Green open access, when needed, has to be enforced by the institutions, arguably for ethical responsibilities for publicly-funded resaerch.</p><h2 id=self-evaluation>Self evaluation</h2><p>To keep this process able to comply with the needs of researchers, post-project meetings to define what worked and what did not, what can be done better, and other criticalities has to be performed. This self-audit has the be accessible for aggregate statistics to be performed, so standard protocols (such as feedback forms) and other techniques should be used.</p><p>Periodically, these guidelines and policies can be changed following researcher feedback. In particular, FIPs can be re-evaluated for relevance and fitness-of-purpose.</p><h2 id=benefits-of-open-research>Benefits of Open Research</h2><p>This research framework has several inherent benefits. I detail some of them here.</p><h3 id=for-researchers>For researchers</h3><ul><li>It allows increased focus on the research problems at hand, and predicts potential pitfalls during the experimental process;</li><li>When the experimental phase starts, Structured protocols significantly ease its execution.</li><li>Careful consideration of every experiment&rsquo;s planning and outcomes limits wasted resources, especially in terms of time.</li><li>Centralized places to store and structure all outcomes of experiments reduces confusions and limits the possibility of accidentally losing data;</li><li>The creation of the project plan can align all contributors to the project on its goals, expected outcomes and procedures.</li><li>For projects with many experimenters, the project plan can help to subdivide work into packages more effectively, and distribute these to different people/groups/organizations.</li><li>Routinely creating high-quality project plans, even for master students, can help when eventually dealing with funding agencies.</li><li>Structured protocols and specifically the creation of interpretations can ease the creation of high-quality manuscripts.</li><li>The creation of nanopublications increases the reach and visibility of one&rsquo;s own research.</li><li>More granular and insightful consideration of the knowledge derived from each experiment can promote increased awareness of one&rsquo;s own work.</li><li>Predetermined data handling and analysis procedures can reduce potential errors, such as data loss or the application of inopportune statistical tools.</li></ul><h3 id=for-the-community>For the community</h3><ul><li>FAIR data enables interoperability and FAIR orchestration services to be built on top of it.</li><li>The repository of curated FIPs and Structured protocols can be reused by the community to increase the quality and FAIRness of their own data;</li><li>Transparency in the experimental process can allow faster review of the material;</li><li>Pre-registering studies allow for collaborations to form between members of the community;</li><li>FAIR data reuse limits wasteful experimentation.</li><li>The FAIR data limits the difficulty of data munging.</li><li>Availability of negative results together with positive ones enables more insight when running large-scale meta-analyses.</li></ul><h3 id=for-institutions-and-funding-agencies>For institutions and funding agencies</h3><ul><li>Keeping track of the number of projects created and followed through can be used as a quality metric;</li><li>The ever-increasing body of FAIR data can be a strong political asset when dealing with funding agencies and international consortia;</li><li>Granular statistics on the <em>actual</em> scientific production (number, type, scope of data gathering or processing) of every member of the institution can be derived from the metadata, enabling greater insight on the organization itself;</li><li>The intervention of external data stewards can limit the possibility of scientific fraud, and the resulting social, political and financial downsides for the institution;</li></ul><h3 id=for-society>For society</h3><ul><li>Citizens can access the knowledge that they funded, in a transparent way;</li><li>Citizen scientists can tap into data that they could not otherwise produce on their own;</li><li>A transparent research process can increase societal trust to science, especially in times of crises.</li><li>Governments can access the available data to inform political action, e.g. in the public health or environmental sciences.</li></ul></section><div class=post-tags></div></article></main><footer><div style=display:flex><a class=soc href=https://github.com/MrHedmad/ rel=me title=GitHub><i data-feather=github></i></a>
<a class=border></a></div><div class=footer-info>2024 CC-BY 4.0 - Luca Visentin - 2024</div></footer><script>feather.replace()</script></div></body></html>